{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "stroke\n"
     ]
    }
   ],
   "source": [
    "dataset = os.path.join(os.getcwd(), \"pdataset\")\n",
    "data = []\n",
    "for i , value in enumerate(os.listdir(dataset)):\n",
    "    print(value)\n",
    "    f_dir = os.path.join(dataset,value)\n",
    "    for each in os.listdir(f_dir):\n",
    "        image = cv2.imread(os.path.join(f_dir,each),0)\n",
    "        image = cv2.resize(image,(200,200))\n",
    "        data.append((image,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(data)\n",
    "x = []\n",
    "y = []\n",
    "for features , label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x = np.array(x).reshape(-1,200,200,1)\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(x,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540 samples, validate on 232 samples\n",
      "Epoch 1/15\n",
      "540/540 [==============================] - 3s 5ms/sample - loss: 0.6837 - acc: 0.5889 - val_loss: 0.6536 - val_acc: 0.6336\n",
      "Epoch 2/15\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.6586 - acc: 0.6352 - val_loss: 0.6588 - val_acc: 0.6466\n",
      "Epoch 3/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6459 - acc: 0.6426 - val_loss: 0.6392 - val_acc: 0.6336\n",
      "Epoch 4/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6204 - acc: 0.6519 - val_loss: 0.6095 - val_acc: 0.6552\n",
      "Epoch 5/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.5653 - acc: 0.6889 - val_loss: 0.5834 - val_acc: 0.6810\n",
      "Epoch 6/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4942 - acc: 0.7370 - val_loss: 0.5334 - val_acc: 0.7026\n",
      "Epoch 7/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4311 - acc: 0.7889 - val_loss: 0.5269 - val_acc: 0.7500\n",
      "Epoch 8/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3666 - acc: 0.8222 - val_loss: 0.5047 - val_acc: 0.7716\n",
      "Epoch 9/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3914 - acc: 0.8259 - val_loss: 0.5604 - val_acc: 0.7155\n",
      "Epoch 10/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3203 - acc: 0.8574 - val_loss: 0.4904 - val_acc: 0.8103\n",
      "Epoch 11/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.2866 - acc: 0.8778 - val_loss: 0.5731 - val_acc: 0.7716\n",
      "Epoch 12/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.2321 - acc: 0.9130 - val_loss: 0.5529 - val_acc: 0.7845\n",
      "Epoch 13/15\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.2001 - acc: 0.9370 - val_loss: 0.5283 - val_acc: 0.8060\n",
      "Epoch 14/15\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1733 - acc: 0.9426 - val_loss: 0.4687 - val_acc: 0.8362\n",
      "Epoch 15/15\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1928 - acc: 0.9204 - val_loss: 0.4900 - val_acc: 0.8276\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs\\\\scalars\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "model.fit(X, y, batch_size=32, epochs=15, validation_split=0.3,  callbacks=[tensorboard_callback])\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 198, 198, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 97, 97, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 474,721\n",
      "Trainable params: 474,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptest(path):\n",
    "    image = cv2.imread(path,0)\n",
    "    image = cv2.resize(image,(200,200))\n",
    "    x = np.array(image).reshape(-1,200,200,1)\n",
    "    y = model.predict_classes(x)\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal expected 0 : observerd ->\n",
      "26.jpg  ->  0\n",
      "32.jpg  ->  0\n",
      "70.jpg  ->  0\n",
      "stroke expected 1 : observerd ->\n",
      "103.jpg  ->  1\n",
      "148.jpg  ->  0\n",
      "249.jpg  ->  0\n",
      "253.jpg  ->  1\n",
      "278.jpg  ->  1\n"
     ]
    }
   ],
   "source": [
    "for i , each in enumerate(os.listdir(\"ptest\")): #[ \"normal\" = 0,\"stroke\" = 1]\n",
    "    print(each,f\"expected {i} : observerd ->\")\n",
    "\n",
    "    for file in os.listdir(f\"ptest/{each}\"):\n",
    "        print(file,\" -> \",ptest(f\"ptest/{each}/\"+file))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
