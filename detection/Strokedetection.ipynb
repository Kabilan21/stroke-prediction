{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.path.join(os.getcwd(), \"pdataset\")\n",
    "data = []\n",
    "for i , value in enumerate(os.listdir(dataset)):\n",
    "    print(value)\n",
    "    f_dir = os.path.join(dataset,value)\n",
    "    for each in os.listdir(f_dir):\n",
    "        image = cv2.imread(os.path.join(f_dir,each),0)\n",
    "        image = cv2.resize(image,(200,200))\n",
    "        data.append((image,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(data)\n",
    "x = []\n",
    "y = []\n",
    "for features , label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "x = np.array(x).reshape(-1,200,200,1)\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(x,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540 samples, validate on 232 samples\n",
      "Epoch 1/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.6725 - acc: 0.6333 - val_loss: 0.6596 - val_acc: 0.6336\n",
      "Epoch 2/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6642 - acc: 0.6333 - val_loss: 0.6535 - val_acc: 0.6336\n",
      "Epoch 3/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6412 - acc: 0.6333 - val_loss: 0.6614 - val_acc: 0.6336\n",
      "Epoch 4/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6317 - acc: 0.6463 - val_loss: 0.6386 - val_acc: 0.6336\n",
      "Epoch 5/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.6024 - acc: 0.6444 - val_loss: 0.6187 - val_acc: 0.6810\n",
      "Epoch 6/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.5746 - acc: 0.6815 - val_loss: 0.5990 - val_acc: 0.6681\n",
      "Epoch 7/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.5313 - acc: 0.7222 - val_loss: 0.5923 - val_acc: 0.6724\n",
      "Epoch 8/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.5088 - acc: 0.7426 - val_loss: 0.5516 - val_acc: 0.7284\n",
      "Epoch 9/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.5259 - acc: 0.7167 - val_loss: 0.5351 - val_acc: 0.7284\n",
      "Epoch 10/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4907 - acc: 0.7500 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4866 - acc: 0.7796 - val_loss: 0.5359 - val_acc: 0.7155\n",
      "Epoch 12/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4188 - acc: 0.8093 - val_loss: 0.5709 - val_acc: 0.7198\n",
      "Epoch 13/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.4118 - acc: 0.8000 - val_loss: 0.5172 - val_acc: 0.7328\n",
      "Epoch 14/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3741 - acc: 0.8259 - val_loss: 0.5261 - val_acc: 0.7716\n",
      "Epoch 15/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3579 - acc: 0.8370 - val_loss: 0.5160 - val_acc: 0.7974\n",
      "Epoch 16/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.3209 - acc: 0.8556 - val_loss: 0.5445 - val_acc: 0.7845\n",
      "Epoch 17/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.2662 - acc: 0.8926 - val_loss: 0.5019 - val_acc: 0.8319\n",
      "Epoch 18/50\n",
      "540/540 [==============================] - 2s 3ms/sample - loss: 0.1983 - acc: 0.9278 - val_loss: 0.4837 - val_acc: 0.8060\n",
      "Epoch 19/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1836 - acc: 0.9241 - val_loss: 0.4574 - val_acc: 0.8362\n",
      "Epoch 20/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1424 - acc: 0.9519 - val_loss: 0.5007 - val_acc: 0.8836\n",
      "Epoch 21/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0898 - acc: 0.9741 - val_loss: 0.5671 - val_acc: 0.8276\n",
      "Epoch 22/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0881 - acc: 0.9537 - val_loss: 0.5913 - val_acc: 0.8578\n",
      "Epoch 23/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0813 - acc: 0.9704 - val_loss: 0.6142 - val_acc: 0.8362\n",
      "Epoch 24/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1172 - acc: 0.9704 - val_loss: 0.6822 - val_acc: 0.7845\n",
      "Epoch 25/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.1054 - acc: 0.9574 - val_loss: 0.4526 - val_acc: 0.8879\n",
      "Epoch 26/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0472 - acc: 0.9870 - val_loss: 0.4900 - val_acc: 0.8836\n",
      "Epoch 27/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0237 - acc: 0.9944 - val_loss: 0.5872 - val_acc: 0.9009\n",
      "Epoch 28/50\n",
      "540/540 [==============================] - 3s 5ms/sample - loss: 0.0148 - acc: 0.9963 - val_loss: 0.6074 - val_acc: 0.8836\n",
      "Epoch 29/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0158 - acc: 0.9981 - val_loss: 0.6964 - val_acc: 0.9009\n",
      "Epoch 30/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 0.9181\n",
      "Epoch 31/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.9138\n",
      "Epoch 32/50\n",
      "540/540 [==============================] - 2s 4ms/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6890 - val_acc: 0.9224\n",
      "Epoch 33/50\n",
      "160/540 [=======>......................] - ETA: 1s - loss: 9.8977e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs\\\\scalars\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "model.fit(X, y, batch_size=32, epochs=50, validation_split=0.3,  callbacks=[tensorboard_callback])\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptest(path):\n",
    "    image = cv2.imread(path,0)\n",
    "    image = cv2.resize(image,(200,200))\n",
    "    x = np.array(image).reshape(-1,200,200,1)\n",
    "    y = model.predict_classes(x)\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , each in enumerate(os.listdir(\"ptest\")): #[ \"normal\" = 0,\"stroke\" = 1]\n",
    "    print(each,f\"expected {i} : observerd ->\")\n",
    "\n",
    "    for file in os.listdir(f\"ptest/{each}\"):\n",
    "        print(file,\" -> \",ptest(f\"ptest/{each}/\"+file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
